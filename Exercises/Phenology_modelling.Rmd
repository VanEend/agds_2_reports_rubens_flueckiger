---
title: "Phenology_modelling"
author: "Flueckiger_Rubens"
date: "2025-10-27"
output: 
  html_document:
    toc: TRUE
---

# 1 Introduction

# 2 Load packages and functions

```{r}
library(phenocamr)
library(appeears)
library(sf)
library(dplyr)
library(ggplot2)

source("../functions/GDD_functions.R")
```

# 3 Load data

## 3.1 Load phenocam data

```{r}
#Phenocam data
if(FALSE){ #Prevents re-load
  download_phenocam(
    site = "harvard$",
    veg_type = "DB",
    roi_id = "1000",
    daymet = TRUE,
    phenophase = TRUE,
    trim = 2022,
    out_dir = "../data_raw/" #Store data set in folder
  )
}
```


```{r}
# 1. Temperature information
harvard_data <- read.table(
  "../data_raw/harvard_DB_1000_3day.csv",
  header = T, sep = ",")

# 2. Day of leave out information
harvard_phenology <- read.table(
  "../data_raw/harvard_DB_1000_3day_transition_dates.csv",
  header = T, sep = ","
)
```

### 3.1.1 Preprocess data

```{r}
# Adjust temperature data set
harvard_data <- harvard_data |>
  mutate(
    tmin = tmin..deg.c., #rename
    tmax = tmax..deg.c.,
    tmean = (tmax + tmin)/2
    ) |> #rename
  
  select( #Select only relevant variables
    date, 
    year,
    doy,
    tmax,
    tmin,
    tmean
  ) 

# Adjust day of leave out data set
harvard_phenology <- harvard_phenology |>
  filter(
    direction == "rising",
    gcc_value == "gcc_90"
  ) |>
  
  mutate(
    doy = as.numeric(format(as.Date(transition_25),"%j")),
    year = as.numeric(format(as.Date(transition_25),"%Y"))
  ) |>
  
  select(
    year,
    doy,
    transition_25,
    threshold_25
    )
```

## 3.2 Load NASA data

### 3.2.1 MCD12Q2

```{r}
if(FALSE){ #Prevents re-load
  #Boundries of data set
  xmin <- -72
  xmax <- -70
  ymin <- 42
  ymax <- 44
  
  #Create polygon of data set
  coords <- matrix(c(
    xmin, ymin,
    xmax, ymin,
    xmax, ymax,
    xmin, ymax,
    xmin, ymin  # Closing the polygon by repeating first point
  ), ncol = 2, byrow = TRUE)
  
  # Create a simple feature geometry collection with CRS
  roi <- st_sf(
    geometry = st_sfc(st_polygon(list(coords)),
                      crs = 4326)  # WGS 84
  )
  
  # build the area based request/task
  df <- data.frame(
    task = "MCD12Q2.061_2010",
    subtask = "subtask",
    latitude = NA,
    longitude = NA,
    start = "2010-01-01",
    end = "2010-12-31",
    product = "MCD12Q2.061",
    layer = c("Greenup")
  )
  
  task <- rs_build_task(
    df = df,
    roi = roi,
    format = "geotiff"
  )
  
  # request the task to be executed
  rs_request(
    request = task,
    user = "vaneend",
    transfer = TRUE,
    path = "../data_raw/", #Store data set in folder
    verbose = TRUE
  )
}
```

### 3.2.2 DAYMET

```{r}
if(FALSE){
  # Define the bounding box coordinates
  xmin <- -72; xmax <- -70
  ymin <- 42; ymax <- 44
  coords <- matrix(c(
    xmin, ymin,
    xmax, ymin,
    xmax, ymax,
    xmin, ymax,
    xmin, ymin  # Closing the polygon by repeating first point
  ), ncol = 2, byrow = TRUE)
  
  # Create a simple feature geometry collection with CRS
  roi <- st_sf(
    geometry = st_sfc(st_polygon(list(coords)),
                      crs = 4326)  # WGS 84)
  )
  # build the area based request/task
  df <- data.frame(
    task = "DAYMET.004_2010",
    subtask = "subtask",
    latitude = NA,
    longitude = NA,
    start = "2010-01-01",
    end = "2010-12-31",
    product = "DAYMET.004",
    layer = c("tmax", "tmin")
  )
  task <- rs_build_task(
    df = df,
    roi = roi,
    format = "netcdf4"
  )
  
  # request the task to be executed
  rs_request(
    request = task,
    user = "vaneend",
    transfer = TRUE,
    path = "../data_raw/",
    verbose = TRUE
  )
}
```

# 4 GDD formula

=> Extra sheet

## 4.1 Evaluation

```{r}
#Filter only 2010 of temperature data set
harvard_filter <- harvard_data |>
  filter(year == 2010)

#Calculate GDD
harvard_filter <- harvard_filter |> mutate(
  gdd = cumsum(
    ifelse(tmean >= 5, tmean - 5,
           ifelse(tmax >= 5, (tmax - 5)/2, 0))
  )
)

#Print evolution of GDD
ggplot(data = harvard_filter) +
  geom_point(aes(
    y = gdd,
    x = doy,
    colour = tmean > 0,
    group = 1)
  ) +
  
  #Color positive contribution red and 0 contribution blue
  scale_colour_discrete(type = c("blue", "red")) +
  
  #Limit x-axis range
  xlim(1, 180) +
  
  labs(
    x = "DOY",
    y = "Cumulative GDD [C°]",
    title = "Evolution of the cumulative GDD"
  ) +
  
  theme_bw() +
  theme(
    legend.position = "none"
  )

#Critical cumulative sum value:
doy <- harvard_phenology$doy[
  which(harvard_phenology$year == 2010)
  ]

harvard_filter[doy, "gdd"]
```

# 5 Optimal GDD

## 5.1 LOESS function

=> Extra sheet

## 5.2 SA Optimization

```{r}
# starting model parameters
par = c(5, 157)

# limits to the parameter space
lower <- c(-10,0)
upper <- c(45,600)

# data needs to be provided in a consistent
# single data file, a nested data structure
# will therefore accept non standard data formats
data <- list(
  model = harvard_data,
  validation = harvard_phenology
  )

# optimize the model parameters
optim_par = GenSA::GenSA(
 par = par,
 fn = mae_gdd,
 lower = lower,
 upper = upper,
 control = list(
   max.call = 4000
   ),
 data = data
)$par
```

## 5.3 Output analysis

```{r}
# run the model for all years
# to get the phenology predictions
predictions <- harvard_data |>
  group_by(year) |>
  summarize(
   prediction = gdd_model(
    tmean = tmean,
    tmax = tmax,
    t_ref = optim_par[1],
    gdd_crit = optim_par[2]
  )  
  )

#Add observed values to dataframe
predictions <- na.omit(predictions) |>
  mutate(
    observation = harvard_phenology$doy
  )
```

```{r}
#Extract coefficients of model
fit <- lm(prediction ~ observation, data = predictions)
a <- round(as.numeric(fit$coefficients[2]), 3) #Slope
b <- round(as.numeric(fit$coefficients[1]), 3) #Intercept
```

```{r}
ggplot(data = predictions) +
  geom_point(aes(
    x = observation,
    y = prediction
    )
  ) +
  geom_abline( #Ideal case
    intercept = 0,
    slope = 1,
    linetype = "dotted"
  ) + 
  geom_smooth( #Linear fit to observed cases
    aes(observation, prediction),
    colour = "grey25",
    method = "lm") + 
  labs(
    x = "Observation",
    y = "Prediction",
    subtitle = paste(c("f(x) = ",a ,"x + ",b), sep = "", collapse = "")
  ) +
  theme_bw()
```

# 6 Spatial analysis

## 6.1 Observed result

```{r}
r1 <- terra::rast(
  "../data_raw/MCD12Q2.061_2010/MCD12Q2.061_Greenup_0_doy2010001000000_aid0001.tif"
  )
terra::crs(r1) <- "epsg:4326"

#Extract lowest possible date
val <- as.numeric(as.Date("2010-01-01"))

#Convert into DOY format and NA all values below 01.01.2010
r1 <- terra::ifel(r1 > val, r1, NA) - val
```

```{r}
p1 <- ggplot() +
  tidyterra::geom_spatraster(data = r1) +
  
  #Add legend
  scale_fill_viridis_c(
    na.value = NA,
    name = "DOY"
    ) +
  
  #Due to display issues, manually create tick labels 
  scale_y_continuous(
    name = "Longitude",
    breaks = seq(42, 44, by = 0.5),
    labels = c("42°N", "42.5°N", "43°N", "43.5°N", "44°N")
    ) +
  scale_x_continuous(
    name = "Lattitude",
    breaks = seq(-72, -70, by = 0.5),
    labels = c("72°W", "71.5°W", "71°W", "70.5°W", "70°W")
    ) +
  
  #Add title
  labs(
    title = "Day of leave-out 2010; observed",
    subtitle = "Boston MA, USA"
  ) +
  theme_bw()

p1
```

## 6.2 Predicted result

```{r}
r_temp <- terra::rast("../data_raw/DAYMET.004_2010/DAYMET.004_1km_aid0001.nc")

#Seperate maximum and minimum temperature values
r_tmax <- r_temp["tmax"]
r_tmin <- r_temp["tmin"]

#Subset of first 180 days
r_tmax_sub <- terra::subset(
  r_tmax,
  1:180
)
r_tmin_sub <- terra::subset(
  r_tmin,
  1:180
)

#Create subset of mean temperature values
r_tmean_sub <- terra::mean(r_tmax_sub, r_tmin_sub)
```

1. Split tmax data value in tmax < tref == 0, tmax > tref & tmean < tref == tmax, tmean > tref == 30
2. Cumsum of split tmax data
3. Cumsum of tmean data
4. combine split tmax data and tmean data
5. Apply GDD funciton to data in 4.

=> functions in extra sheet

```{r}
# 1. Pre processing for tmax data
#Check if tmean < ref
phen_check <- terra::app(
  r_tmean_sub,
  fun = tmean_check,
  t_ref = optim_par[1] 
)
#Extract max value of phen_check
phen_check_1 <- terra::mosaic(
  x = r_tmax_sub,
  y = phen_check,
  fun = "max"
)

# 2. Calculate tmax cumsum
phen_pred_max <- terra::app(
  phen_check_1,
  fun = cumsum_tmax,
  t_ref = optim_par[1]
)

# 3. Calculate tmean cumsum
phen_pred_mean <- terra::app(
  r_tmean_sub,
  fun = cumsum_tmean,
  t_ref = optim_par[1]
)


# 4. Combine mean and max data set
phenology_predict <- phen_pred_mean + phen_pred_max

# 5. Apply function onto whole data set
pheno_predic <- terra::app(
  phenology_predict,
  fun = extract_doy,
  gdd_crit = optim_par[2]
)
```

```{r}
#For plotting reset the coordinate reference frame
terra::crs(pheno_predic) <- "epsg:4326"

p2 <- ggplot() +
  tidyterra::geom_spatraster(data = pheno_predic) +
  
  #Legend
  scale_fill_viridis_c( 
    na.value = NA,
    name = "DOY"
    ) +
  
  #Due to display issues, manually create tick labels 
  scale_y_continuous(
    name = "Longitude",
    breaks = seq(42, 44, by = 0.5),
    labels = c("42°N", "42.5°N", "43°N", "43.5°N", "44°N")
    ) +
  scale_x_continuous(
    name = "Lattitude",
    breaks = seq(-72, -70, by = 0.5),
    labels = c("72°W", "71.5°W", "71°W", "70.5°W", "70°W")
    ) +
  
  #Create title
  labs(
    title = "Day of leave-out 2010; predicted",
    subtitle = "Boston MA, USA"
  ) +
  theme_bw()

p2
```

# 7 Discussion

```{r}
#Set dimension for MCD12Q2 data set to be equal to prediction set
dimension <- terra::rast(
  nrows = 226, #Number of rows
  ncols = 226, #Number of colums
  xmin = -72, #Extend
  xmax = -70,
  ymin = 42,
  ymax = 44
  )

r1 <- terra::resample(r1, dimension, method = "bilinear")

#Ste extend of both raster data to be equal
terra::ext(pheno_predic) <- c(-72, -70, 42, 44)
```

```{r}
diff <- pheno_predic - r1

#Set coordinate reference system for plot
terra::crs(diff) <- "epsg:4326"

ggplot() +
  tidyterra::geom_spatraster(data = diff) +
  
  #Legend
  scale_fill_gradient2( #use gradient for better visualisation
    low = "blue4",
    mid = "azure2",
    high = "red4",
    breaks = seq(-30, 90, by = 30),
    na.value = NA,
    name = "DOY"
    ) +
  
  #Due to display issues, manually create tick labels 
  scale_y_continuous(
    name = "Longitude",
    breaks = seq(42, 44, by = 0.5),
    labels = c("42°N", "42.5°N", "43°N", "43.5°N", "44°N")
    ) +
  scale_x_continuous(
    name = "Lattitude",
    breaks = seq(-72, -70, by = 0.5),
    labels = c("72°W", "71.5°W", "71°W", "70.5°W", "70°W")
    ) +
  
  #Create title
  labs(
    title = "Day of leave-out 2010; difference",
    subtitle = "Boston MA, USA"
  ) +
  theme_bw()
```

```{r}
cowplot::plot_grid(p1, p2)
```